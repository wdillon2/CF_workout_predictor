{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\p0key\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import xgboost\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_colwidth',999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make movement dictionary to use in vectorizor and a relationship dictionary to relate movement with movement class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def movements_data(csv_file):\n",
    "    movements = pd.read_csv(csv_file, index_col = 'Unnamed: 0')\n",
    "    # add movements that might have mulitple formats\n",
    "    add_moves = [{'movement':'double-under','frequency':153,'move_class':'Monostructural','Equipment':'jump rope'},{'movement':'squat','frequency':63,'move_class':'Gymnastics','Equipment':'body'}]\n",
    "    am = pd.DataFrame(add_moves)\n",
    "    return pd.concat([movements,am], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_dicts(use): #fill in Dictionary needed 'CV', 'mgw', 'equip', or 'other'\n",
    "    new_move = movements_data('movements.csv')\n",
    "    \n",
    "    if use == 'CV':\n",
    "        move_dict = new_move.movement.to_dict()\n",
    "        return dict((v,k) for k,v in move_dict.iteritems())\n",
    "    \n",
    "    if use == 'mgw' or use == 'equip':\n",
    "        new_move_dict = new_move[['movement','move_class','Equipment']].to_dict(orient='records')\n",
    "        relate_dict = {}\n",
    "        equip_dict = {}\n",
    "        for row in new_move_dict:\n",
    "            relate_dict[row['movement']] = row['move_class']\n",
    "            equip_dict[row['movement']] = row['Equipment']\n",
    "        if use == 'equip':\n",
    "            return equip_dict\n",
    "        else:\n",
    "            return relate_dict\n",
    "    \n",
    "    if use == 'other':\n",
    "        eq_dict = new_move.Equipment.to_dict()\n",
    "        other_dict = dict((v,k) for k,v in eq_dict.iteritems())\n",
    "        bar = [k for k in other_dict.iterkeys()]\n",
    "        for i,k in enumerate(bar):\n",
    "            other_dict[k]=i\n",
    "        return other_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in initial data from Beyond the Whiteboard and locate the rows that represent workouts for time or for reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#takes in data.csv from btwb and converts to the dataframe to use for the model\n",
    "def model_df(data_csv):\n",
    "    df = pd.read_csv(data_csv)\n",
    "    df1 = df.loc[(df['Work performed'] > 0) & (df['Work time'] > 0),:].copy()\n",
    "    return df1.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create functions to feed into Feature Union and Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def base_features_wt(df):\n",
    "    return df[['Work time']]\n",
    "\n",
    "\n",
    "base_features_wt_tf = FunctionTransformer(base_features_wt, validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def base_features_wp(df):\n",
    "    return df[['Work performed']]\n",
    "\n",
    "base_features_wp_tf = FunctionTransformer(base_features_wp, validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_movements(df):\n",
    "    move_in_work = []\n",
    "    new_move = movements_data('movements.csv')\n",
    "    for w in [x for x in df['Description']]:\n",
    "        moves = []\n",
    "        row = {}\n",
    "        for m in new_move.movement:\n",
    "            if m in w.lower():\n",
    "                moves.append(m)\n",
    "        row['move'] = ', '.join(moves)\n",
    "        move_in_work.append(row)\n",
    "    return pd.DataFrame(move_in_work)['move']\n",
    "\n",
    "get_movements_tf = FunctionTransformer(get_movements, validate=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def equipment_used(cell):\n",
    "    equipment_used = []\n",
    "    equip_list = cell.split(', ')\n",
    "    equip_dict = make_dicts('equip')\n",
    "    for x in equip_list:\n",
    "        if x in equip_dict:\n",
    "            equipment_used.append(equip_dict[x])\n",
    "    return ', '.join(sorted(set(equipment_used))) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_equip(df):\n",
    "    return pd.DataFrame(get_movements(df).apply(equipment_used))['move']\n",
    "    \n",
    "get_equip_tf = FunctionTransformer(get_equip, validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mgw_breakdown(cell):\n",
    "    mgw = []\n",
    "    move_list = cell.split(', ')\n",
    "    relate_dict = make_dicts('mgw')\n",
    "    for x in move_list:\n",
    "        if x in relate_dict:\n",
    "            mgw.append(relate_dict[x][0])\n",
    "    return ''.join(sorted(set(mgw)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_move_class(df):\n",
    "    breakdown = pd.DataFrame(get_movements(df).apply(mgw_breakdown)) \n",
    "    for let in ['G','M','W']:\n",
    "        breakdown[let] = breakdown['move'].apply(lambda x: 1 if re.search(let,x) else 0)\n",
    "    return breakdown[['G','M','W']]\n",
    "\n",
    "get_move_class_tf = FunctionTransformer(get_move_class, validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def time_or_reps(df):\n",
    "    time_or_reps = pd.DataFrame(df['Formatted Result'].apply(lambda x: 'Time' if re.search(r'(min|sec)', x) else 'Reps'))\n",
    "    return pd.get_dummies(time_or_reps, prefix='For')\n",
    "\n",
    "time_or_reps_tf = FunctionTransformer(time_or_reps, validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_prescribed(df):\n",
    "    return df['Prescribed'].apply(int).to_frame()\n",
    "\n",
    "is_prescribed_tf = FunctionTransformer(is_prescribed, validate=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_year(df):\n",
    "    years = pd.Categorical(pd.to_datetime(df['Date']).dt.year, categories = range(2011,2018))\n",
    "    return pd.get_dummies(years, columns=['Date'], prefix='Year')\n",
    "\n",
    "get_year_tf = FunctionTransformer(get_year, validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_month(df):\n",
    "    months = pd.DataFrame(pd.to_datetime(df['Date']).dt.month)\n",
    "    return pd.get_dummies(months, columns=['Date'], prefix='Month')\n",
    "\n",
    "get_month_tf = FunctionTransformer(get_month, validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "equip_pipeline = Pipeline([\n",
    "    ('get_equip', get_equip_tf),\n",
    "    ('eq_vect', CountVectorizer(vocabulary=make_dicts('eq'))),\n",
    "    ('eq_nonsparse',FunctionTransformer(lambda X: X.toarray(), validate=False)) \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vector_pipeline = Pipeline([\n",
    "    ('get_movements', get_movements_tf),\n",
    "    ('vect', CountVectorizer(vocabulary=make_dicts('CV'))),\n",
    "    ('nonsparse',FunctionTransformer(lambda X: X.toarray(), validate=False)) \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_wt = FeatureUnion([\n",
    "    #('get_month', get_month_tf),\n",
    "    #('get_year', get_year_tf),\n",
    "    ('equip_pipeline', equip_pipeline),\n",
    "    #('is_prescribed', is_prescribed_tf),\n",
    "    #('time_or_reps', time_or_reps_tf),\n",
    "    ('get_move_class', get_move_class_tf),\n",
    "    ('vector_pipeline', vector_pipeline),\n",
    "    ('base_features_wt', base_features_wt_tf)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_wp = FeatureUnion([\n",
    "    #('get_month', get_month_tf),\n",
    "    #('get_year', get_year_tf),\n",
    "    ('equip_pipeline', equip_pipeline),\n",
    "    #('is_prescribed', is_prescribed_tf),\n",
    "    #('time_or_reps', time_or_reps_tf),\n",
    "    ('get_move_class', get_move_class_tf),\n",
    "    ('vector_pipeline', vector_pipeline),\n",
    "    ('base_features_wp', base_features_wp_tf)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe_wt = Pipeline([\n",
    "    ('features_wt', features_wt),\n",
    "    #('ss', StandardScaler()),\n",
    "    #('lr', LinearRegression(fit_intercept=False, normalize=True))\n",
    "    #('rf', RandomForestRegressor())\n",
    "    ('gb', GradientBoostingRegressor())\n",
    "    #('dt', DecisionTreeRegressor())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe_wp = Pipeline([\n",
    "    ('features_wp', features_wp),\n",
    "    #('ss', StandardScaler()),\n",
    "    #('lr', LinearRegression(fit_intercept=False, normalize=True))\n",
    "    #('rf', RandomForestRegressor())\n",
    "    ('gb', GradientBoostingRegressor())\n",
    "    #('dt', DecisionTreeRegressor())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_prediction(discription,wt,wp):\n",
    "    #disription is workout discription, wt = worktime given for AMRAPs, wp = work performed for RFT\n",
    "    df1 = model_df('data.csv')\n",
    "    test = [{'Work time': wt, 'Description': discription, 'Work performed': wp}]\n",
    "    df1 = df1.append(test, ignore_index=True)\n",
    "    vect = TfidfVectorizer()\n",
    "\n",
    "    tfid_matrix = vect.fit_transform(df1['Description'])\n",
    "    des_distance = pairwise_distances(tfid_matrix, metric='cosine')\n",
    "    new_df = pd.DataFrame(des_distance, index=df1.index.values, columns=df1['Description'].values)\n",
    "    cos_sim = new_df[discription][new_df[discription]<0.87]\n",
    "    if len(cos_sim.shape) > 1:\n",
    "        s = new_df[discription].mean(axis=1)\n",
    "        cos_sim = s[s<0.25]\n",
    "    #if cos_sim.min < 0.25:\n",
    "        #cos_sim = cos_sim[cos_sim < 0.25]\n",
    "    print cos_sim.shape\n",
    "    df_test=df1.iloc[list(cos_sim[:-1].index),:].copy()\n",
    "\n",
    "    if wt:  \n",
    "        pipe_wt.fit(df_test,df_test['Work performed'])\n",
    "\n",
    "        return pipe_wt.predict(pd.DataFrame(test))\n",
    "    if wp:  \n",
    "        pipe_wp.fit(df_test,df_test['Work time'])\n",
    "        return pipe_wp.predict(df1.iloc[df1.shape[0]-1:df1.shape[0],:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_formatted_pred(discription, wt, wp, round_reps, round_work):\n",
    "    raw_result = get_prediction(discription, wt, wp)\n",
    "    #return raw_result\n",
    "    if wt:\n",
    "        tot_rounds = raw_result / round_work\n",
    "        splits = str(tot_rounds[0]).split('.')\n",
    "        formatted_result = '{} rounds + {} reps'.format(splits[0],round(float('.'+splits[1])*round_reps,0))\n",
    "        return formatted_result\n",
    "    if wp:\n",
    "        seconds = (raw_result[0] / 1000)%60\n",
    "        minutes = ((raw_result[0] / 1000) - seconds)/60\n",
    "        return '{} min, {} sec'.format(minutes,round(seconds,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3 rounds + 15.0 reps'"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_formatted_pred('12:00 AMRAP:10 Back Squats, 95 lbs 10 Russian Kettlebell Swings, 53 lbs 10 Back Squats, 95 lbs 20 Push-up (knees)s',720000,0,50,9319)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(151L,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'10.0 min, 3.22 sec'"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_formatted_pred('30 Clean & Jerks, 65 lbs',0,19500,None,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156L,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'9.0 min, 2.65 sec'"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_formatted_pred('''50 Double Unders \n",
    "50 AbMat Sit-ups\n",
    "40 Double Unders\n",
    "40 AbMat Sit-ups\n",
    "30 Double Unders\n",
    "30 AbMat Sit-ups\n",
    "20 Double Unders\n",
    "20 AbMat Sit-ups\n",
    "10 Double Unders\n",
    "10 AbMat Sit-ups''', 0,38027,None,None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38027.6"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "92.3*412"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "df1 = model_df('data.csv')\n",
    "\n",
    "test_d = '7:00 AMRAP: 7 Ring Push-ups 10 Wall Balls, 8lbs'\n",
    "test = [{'Work time': 420000.0, 'Description': test_d}]\n",
    "pd.DataFrame(test)\n",
    "\n",
    "df1 = df1.append(test, ignore_index=True)\n",
    "\n",
    "vect = TfidfVectorizer()\n",
    "\n",
    "tfid_matrix = vect.fit_transform(df1['Description'])\n",
    "des_distance = pairwise_distances(tfid_matrix, metric='cosine')\n",
    "new_df = pd.DataFrame(des_distance, index=df1.index.values, columns=df1['Description'].values)\n",
    "new_df[test_d].sort_values()[:300]\n",
    "\n",
    "df_test=df1.iloc[list((new_df[test_d].sort_values()[1:300].index)),:]\n",
    "\n",
    "pipe_wt.fit(df_test,df_test['Work performed'])\n",
    "\n",
    "pred = pipe_wt.predict(df1.iloc[742:743,:])\n",
    "pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "\n",
    "kf = KFold(n_splits=3, shuffle= True ,random_state=2003)\n",
    "\n",
    "#cross_val_score(pipe, df1, y=df1['Work performed'], cv=kf, verbose=True).mean()\n",
    "params = {\n",
    "    'gb__loss': ['ls','lad'],\n",
    "    'gb__n_estimators': [100,200,300],\n",
    "    'gb__max_depth': [3,4,5]\n",
    "}\n",
    "gs = GridSearchCV(pipe, param_grid={}, cv=kf)\n",
    "gs.fit( df_test, df_test['Work performed'])\n",
    "print gs.best_score_\n",
    "print gs.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
